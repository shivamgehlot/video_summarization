# ğŸ¬ AI Video Summarizer

An end-to-end local AI system that converts long videos into clean, structured summaries.

The application accepts **YouTube URLs or uploaded video files**, extracts speech, understands the content using a local LLM, and generates a human-readable summary.

This project demonstrates real AI engineering concepts: data ingestion â†’ preprocessing â†’ speech recognition â†’ long-context reasoning â†’ UI delivery.

---

## âœ¨ Features

* ğŸ¥ Upload video files (mp4, mkv, mov, avi)
* ğŸ”— Paste YouTube URL
* ğŸ”Š Direct audio extraction (no full video download required)
* ğŸ§  Speech-to-Text using Faster-Whisper
* ğŸ§¹ Transcript cleaning & noise removal
* ğŸ“š Adaptive chunking for long videos
* ğŸ¤– Local LLM summarization (Qwen GGUF via llama.cpp)
* ğŸ–¥ï¸ Streamlit interactive UI
* ğŸ’» Fully offline AI inference (no paid APIs)

---

## ğŸ§  System Architecture

User Input â†’ Audio Extraction â†’ Transcription â†’ Cleaning â†’ Chunking â†’ LLM Reasoning â†’ Structured Summary

```
User (Upload / URL)
        â†“
yt-dlp / File Handler
        â†“
FFmpeg Audio Processing
        â†“
Whisper Transcription
        â†“
Transcript Cleaning
        â†“
Chunking (long context handling)
        â†“
Qwen Local LLM
        â†“
Structured Summary Output
        â†“
Streamlit UI
```

---

## ğŸ—‚ï¸ Project Structure

```
video_summarization/
â”‚   app.py                 # Streamlit UI
â”‚   main.py                # Pipeline orchestrator
â”‚   requirements.txt
â”‚
â””â”€â”€ src/
    audio_transcriber.py   # Whisper STT
    extract_audio.py       # FFmpeg processing
    input_handler.py       # URL & upload handler
    text_cleaner.py        # Noise removal
    chunker.py             # Long text splitter
    text_summarizer.py     # Qwen summarization
```

---

## âš™ï¸ Installation

### 1. Clone repository

```
git clone https://github.com/<your-username>/video_summarization.git
cd video_summarization
```

### 2. Create virtual environment

```
python -m venv venv
venv\Scripts\activate
```

### 3. Install dependencies

```
pip install -r requirements.txt
```

---

## ğŸ”§ Install FFmpeg (Required)

Download:
https://www.gyan.dev/ffmpeg/builds/

Add `ffmpeg/bin` to system PATH

Verify:

```
ffmpeg -version
```

---

## ğŸ¤– Download LLM Model

The project uses a local quantized model:

**Qwen2.5-1.5B-Instruct-GGUF**

The model automatically downloads on first run and is cached locally.

---

## â–¶ï¸ Run Application

```
streamlit run app.py
```

Then open:

```
http://localhost:8501
```

---

## ğŸ“Š Example Output

The system generates:

* Video type detection
* Main topic
* Key points
* Important details
* Final clean summary

---

## ğŸ§© Technologies Used

| Component          | Technology               |
| ------------------ | ------------------------ |
| Speech Recognition | Faster-Whisper           |
| LLM                | Qwen2.5 GGUF (llama.cpp) |
| Video Processing   | FFmpeg                   |
| YouTube Download   | yt-dlp                   |
| Backend Logic      | Python                   |
| UI                 | Streamlit                |

---

## ğŸš€ Future Improvements

* Timestamped chapter generation
* Highlight extraction (key moments)
* Subtitle (.srt) generation
* Multilingual summarization
* FastAPI model server deployment
* Vector database search inside videos

---

## ğŸ‘¨â€ğŸ’» Author

**Shivam Gehlot**

Aspiring AI Engineer focused on building practical ML systems and local-AI applications.

---

## ğŸ“œ License

MIT License
